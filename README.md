<<<<<<< HEAD
# MNA_MLOps

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

Proyecto MLOps Equipo 43: PredicciÃ³n del Consumo de EnergÃ­a en la Ciudad de TetuÃ¡n, Marruecos.

## Project Organization

```
â”œâ”€â”€ LICENSE            <- Open-source license if one is chosen
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from third party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
â”‚
â”œâ”€â”€ docs               <- A default mkdocs project; see www.mkdocs.org for details
â”‚
â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-jqp-initial-data-exploration`.
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for 
â”‚                         Project and configuration for tools like black
â”‚
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `pip freeze > requirements.txt`
â”‚
â”œâ”€â”€ setup.cfg          <- Configuration file for flake8
â”‚
â””â”€â”€ Project   <- Source code for use in this project.
    â”‚
    â”œâ”€â”€ __init__.py             <- Makes Project a Python module
    â”‚
    â”œâ”€â”€ config.py               <- Store useful variables and configuration
    â”‚
    â”œâ”€â”€ dataset.py              <- Scripts to download or generate data
    â”‚
    â”œâ”€â”€ features.py             <- Code to create features for modeling
    â”‚
    â”‚   â”œâ”€â”€ __init__.py 
    â”‚   â”œâ”€â”€ predict.py          <- Code to run model inference with trained models          
    â”‚   â””â”€â”€ train.py            <- Code to train models
    â”‚
    â””â”€â”€ plots.py                <- Code to create visualizations
```

--------


# âš¡ï¸ Proyecto MLOps: PredicciÃ³n del Consumo de EnergÃ­a en la Ciudad de TetuÃ¡n (Marruecos)

Este proyecto aborda la tarea de predicciÃ³n de series de tiempo para el consumo de energÃ­a en TetuÃ¡n, Marruecos, utilizando un conjunto de datos pÃºblico y aplicando un flujo de trabajo de Machine Learning (ML) detallado.

---

## Prerequisitos

### Instalando y configurando DVC, para control de versiones de nuestros datasets

1. Se instalaron las librerÃ­as dvc y dvc_gdrive, dentro de nuestro ambiente virtual.
2. Se generÃ³ un repositorio (carpeta) dentro de Google Drive.
3. Se creÃ³ una cuenta de Google Cloud Platform.
4. Se creÃ³ un proyecto dentro de nuestra nueva cuenta.
5. Se habilitÃ³ el API de Google Drive dentro de nuestro proyecto.
6. Se creÃ³ y se configurÃ³ un Cliente OAuth.
7. Se utilizaron las credenciales de este cliente para configurar DVC (con Google Drive) dentro del repositorio.

## 1. DescripciÃ³n del Conjunto de Datos

El conjunto de datos **Power Consumption of Tetouan City** es una serie de tiempo multivariada donada al Repositorio de Machine Learning de UCI. Las mediciones son cruciales para la gestiÃ³n eficiente de la energÃ­a en la ciudad.

### 1.1. Resumen de CaracterÃ­sticas

| CaracterÃ­stica | DescripciÃ³n |
| :--- | :--- |
| **Origen** | SCADA System de Amendis (operador de servicio pÃºblico), TetuÃ¡n, Marruecos. |
| **Tipo** | Serie de Tiempo Multivariada, RegresiÃ³n. |
| **PerÃ­odo** | Un aÃ±o completo, desde el 1 de enero de 2017 hasta el 30 de diciembre de 2017. |
| **Frecuencia**| Observaciones registradas en ventanas de **10 minutos**. |
| **Referencia** | [Power Consumption of Tetouan City (UCI Machine Learning Repository)](https://archive.ics.uci.edu/dataset/849/power+consumption+of+tetouan+city). |

### 1.2. Tabla de Variables

| Variable Name | Rol | Tipo | DescripciÃ³n | Â¿Valores Faltantes? |
| :--- | :--- | :--- | :--- | :--- |
| `DateTime` | CaracterÃ­stica | Fecha | Cada diez minutos | no |
| `Temperature` | CaracterÃ­stica | Continua | Temperatura climÃ¡tica de la ciudad de TetuÃ¡n | no |
| `Humidity` | CaracterÃ­stica | Continua | Humedad climÃ¡tica de la ciudad de TetuÃ¡n | no |
| `Wind Speed` | CaracterÃ­stica | Continua | Velocidad del viento de la ciudad de TetuÃ¡n | no |
| `general diffuse flows` | CaracterÃ­stica | Continua | Flujos difusos generales | no |
| `diffuse flows` | CaracterÃ­stica | Continua | Flujos difusos | no |
| `Zone 1 Power Consumption` | Destino | Continua | Consumo de energÃ­a de la zona 1 de la ciudad de TetuÃ¡n | no |
| `Zone 2 Power Consumption` | Destino | Continua | Consumo de energÃ­a de la zona 2 de la ciudad de TetuÃ¡n | no |
| `Zone 3 Power Consumption` | Destino | Continua | Consumo de energÃ­a de la zona 3 de la ciudad de TetuÃ¡n | no |

---

## 2. Flujo de Trabajo de Limpieza y Preprocesamiento
El anÃ¡lisis detallado en el notebook (`ProyectoFase1.ipynb`) se centra en la preparaciÃ³n exhaustiva de los datos para el modelado.

### A. Limpieza de Datos CrÃ­ticos

* **ConversiÃ³n de Tipos:** Se transformaron las columnas numÃ©ricas (e.g., `Temperature`, `Humidity`, `PowerConsumption_ZoneX`) de tipo `object` a `float64`. Esta conversiÃ³n incluyÃ³ la limpieza de cadenas de texto reemplazando comas (`,`) por puntos (`.`).
* **Manejo de Columna Mixta:** La columna `mixed_type_col` (que contenÃ­a datos de texto como `unknown`, `bad`, y `nan`) se eliminÃ³ debido a su naturaleza confusa y baja fracciÃ³n numÃ©rica $(\approx 70\%)$.
    * Los `NaN` en la serie de tiempo se imputaron basÃ¡ndose en sus vecinos inmediatos (valores anteriores y siguientes).
    * Si la diferencia entre dos timestamps vÃ¡lidos era exactamente 20 minutos, el punto intermedio (10 minutos) se usÃ³ para rellenar el vacÃ­o.
    * Para otros faltantes, se calculÃ³ el punto medio (promedio de los nanosegundos) de los timestamps vecinos para la imputaciÃ³n.
* **Manejo de Duplicados Temporales:** Se identificaron y eliminaron los *timestamps* duplicados (1045 filas duplicadas). Se conservÃ³ la fila duplicada que tenÃ­a el mayor nÃºmero de valores no nulos (mayor puntuaciÃ³n de informaciÃ³n).

### B. Tratamiento de Valores AtÃ­picos (Outliers)

* **DetecciÃ³n:** Los valores atÃ­picos en las variables numÃ©ricas se definieron utilizando el mÃ©todo del **Rango IntercuartÃ­lico (IQR)** ($1.5 \times IQR$).
* **ImputaciÃ³n:** Los outliers detectados fueron reemplazados por la **mediana mÃ³vil** calculada en una ventana temporal de 25 perÃ­odos (lo que ayuda a preservar las tendencias locales de la serie de tiempo). En caso de que la mediana mÃ³vil no estuviera disponible, se usÃ³ la mediana global de la columna para la imputaciÃ³n.

### C. IngenierÃ­a de CaracterÃ­sticas


* `DayWeek` (DÃ­a de la Semana).
* `QuarterYear` (Trimestre del AÃ±o).
* `DayYear` (DÃ­a del AÃ±o).

---

## 3. Modelado y EvaluaciÃ³n

### A. ConfiguraciÃ³n

* **Variable Objetivo (`Y`):** Se seleccionÃ³ **`PowerConsumption_Zone2`** para la predicciÃ³n.
* **DivisiÃ³n de Datos:** Se utilizÃ³ una divisiÃ³n por Ã­ndice (no aleatoria) de **80% para entrenamiento** (`x_train`) y **20% para prueba** (`x_test`), respetando la secuencia temporal.

### B. Pipeline de Preprocesamiento
Un `ColumnTransformer` fue configurado para manejar el conjunto de entrenamiento:
1.  **ImputaciÃ³n:** ImputaciÃ³n de nulos restantes con la mediana.
2.  **Escalado:** Se aplicÃ³ **MinMaxScaler** a las variables meteorolÃ³gicas (e.g., `Temperature`, `Humidity`, `WindSpeed`) con un rango de $(1, 2)$.
3.  **Variables Temporales:** Las caracterÃ­sticas temporales creadas (`Day`, `Hour`, etc.) se pasaron directamente al modelo (`remainder='passthrough'`).

### C. Modelo y Resultados

Se utilizÃ³ el algoritmo **RandomForestRegressor** con hiperparÃ¡metros especÃ­ficos (ej. `n_estimators=700`, `max_features=3`).

| Etapa | MÃ©trica | Resultado |
| :--- | :--- | :--- |
| **ValidaciÃ³n Cruzada** | RMSE (Repetido K-Fold) | $864.586 \pm 21.037$ |
| **EvaluaciÃ³n Final (Test)** | RMSE (Error CuadrÃ¡tico Medio RaÃ­z) | $3736.559$ |
| **EvaluaciÃ³n Final (Test)** | MAPE (Error Porcentual Absoluto Medio) | $11.222\%$ |

**Nota sobre los Resultados:** La diferencia entre el RMSE de Cross-Validation y el RMSE de la evaluaciÃ³n final del Test Set sugiere una posible **sobreestimaciÃ³n** del rendimiento durante el entrenamiento, o que el conjunto de prueba (los Ãºltimos meses del aÃ±o) presenta patrones de consumo mÃ¡s difÃ­ciles de predecir.
=======
# ğŸš€ Proyecto MLOps Mejorado - PredicciÃ³n de EnergÃ­a ElÃ©ctrica

## ğŸ“‹ InformaciÃ³n del Proyecto

**Equipo:** 43  
**Programa:** MNA (MaestrÃ­a en Inteligencia Artificial Aplicada)  
**Dataset:** Consumo de energÃ­a elÃ©ctrica en TetuÃ¡n, Marruecos  
**Objetivo:** Desarrollar un pipeline completo de MLOps para predicciÃ³n de consumo energÃ©tico

## ğŸ¯ Objetivos del Proyecto

### Objetivos Principales
- âœ… Implementar una **estructura mejorada de MLOps** siguiendo mejores prÃ¡cticas
- âœ… Realizar **anÃ¡lisis exploratorio de datos** mÃ¡s profundo y comprehensivo  
- âœ… Aplicar **ingenierÃ­a de caracterÃ­sticas** avanzada para series temporales
- âœ… Desarrollar **mÃºltiples modelos** con optimizaciÃ³n de hiperparÃ¡metros
- âœ… Implementar **versionado de datos** con DVC
- âœ… Integrar **seguimiento de experimentos** con MLflow
- âœ… Lograr **mejores resultados de performance** que el proyecto base

### Lineamientos MLOps Implementados
1. **ManipulaciÃ³n de datos:** Pipelines automatizados y reproducibles
2. **EDA (AnÃ¡lisis Exploratorio):** AnÃ¡lisis comprehensivo con visualizaciones avanzadas
3. **Preprocesamiento:** Estrategias robustas para series temporales
4. **Versionado:** Control de versiones de datos, cÃ³digo y modelos
5. **ConstrucciÃ³n de modelos:** MÃºltiples algoritmos con validaciÃ³n rigurosa

## ğŸ“Š Dataset

**Fuente:** Consumo de energÃ­a elÃ©ctrica en TetuÃ¡n, Marruecos  
**CaracterÃ­sticas:**
- Variables climÃ¡ticas (temperatura, humedad, velocidad del viento)
- Variables de radiaciÃ³n solar
- Variable objetivo: Consumo de energÃ­a elÃ©ctrica
- Datos temporales para anÃ¡lisis de series de tiempo

## ğŸ—ï¸ Arquitectura del Proyecto

```
ğŸ“¦ Proyecto_MLOps_Mejorado_Equipo43/
â”œâ”€â”€ ğŸ“ config/                    # Configuraciones
â”‚   â””â”€â”€ config.yaml              # ConfiguraciÃ³n principal
â”œâ”€â”€ ğŸ“ data/                     # Datos (versionados con DVC)
â”‚   â”œâ”€â”€ raw/                     # Datos originales
â”‚   â”œâ”€â”€ interim/                 # Datos intermedios
â”‚   â”œâ”€â”€ processed/               # Datos procesados
â”‚   â””â”€â”€ external/                # Datos externos
â”œâ”€â”€ ğŸ“ experiments/              # Resultados de experimentos
â”œâ”€â”€ ğŸ“ logs/                     # Logs del sistema
â”œâ”€â”€ ğŸ“ mlruns/                   # Tracking de MLflow
â”œâ”€â”€ ğŸ“ models/                   # Modelos entrenados
â”œâ”€â”€ ğŸ“ notebooks/                # Notebooks Jupyter
â”‚   â”œâ”€â”€ 01_EDA_Comprehensivo.ipynb
â”‚   â”œâ”€â”€ 02_Preprocesamiento_Avanzado.ipynb
â”‚   â”œâ”€â”€ 03_Ingenieria_Caracteristicas.ipynb
â”‚   â”œâ”€â”€ 04_Entrenamiento_Modelos.ipynb
â”‚   â”œâ”€â”€ 05_Evaluacion_Performance.ipynb
â”‚   â””â”€â”€ 06_Pipeline_Completo.ipynb
â”œâ”€â”€ ğŸ“ references/               # DocumentaciÃ³n y referencias
â”œâ”€â”€ ğŸ“ reports/                  # Reportes y visualizaciones
â”‚   â””â”€â”€ figures/                 # GrÃ¡ficos generados
â”œâ”€â”€ ğŸ“ scripts/                  # Scripts de utilidad
â”œâ”€â”€ ğŸ“ src/                      # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ data/                    # MÃ³dulos de datos
â”‚   â”œâ”€â”€ features/                # IngenierÃ­a de caracterÃ­sticas
â”‚   â”œâ”€â”€ models/                  # Modelos ML
â”‚   â”œâ”€â”€ utils/                   # Utilidades
â”‚   â”œâ”€â”€ visualization/           # Visualizaciones
â”‚   â””â”€â”€ main_pipeline.py         # Pipeline principal
â”œâ”€â”€ ğŸ“ tests/                    # Tests unitarios
â”œâ”€â”€ requirements.txt             # Dependencias Python
â”œâ”€â”€ pyproject.toml              # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ Makefile                    # Comandos automatizados
â””â”€â”€ README.md                   # Este archivo
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1ï¸âƒ£ Clonar el Repositorio
```bash
git clone <repository-url>
cd Proyecto_MLOps_Mejorado_Equipo43
```

### 2ï¸âƒ£ Crear Entorno Virtual
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

### 3ï¸âƒ£ Instalar Dependencias
```bash
pip install -r requirements.txt
# O usando make
make install
```

### 4ï¸âƒ£ Configurar DVC (Versionado de Datos)
```bash
make setup-dvc
```

### 5ï¸âƒ£ Configurar MLflow (Tracking de Experimentos)
```bash
mlflow ui --host 0.0.0.0 --port 5000
# O usando make
make mlflow-ui
```

## ğŸ”„ Pipeline de MLOps

### Flujo Completo
```bash
# 1. Procesar datos
make data-process

# 2. Entrenar modelos
make train

# 3. Evaluar modelos
make evaluate

# 4. Pipeline completo
make run-pipeline
```

### Comandos Individuales
```bash
# AnÃ¡lisis exploratorio
jupyter lab notebooks/01_EDA_Comprehensivo.ipynb

# Entrenamiento especÃ­fico
python src/main_pipeline.py --stage train --model xgboost

# EvaluaciÃ³n
python src/main_pipeline.py --stage evaluate
```

## ğŸ“ˆ Modelos Implementados

### Algoritmos Base
- **Random Forest:** Robusto para caracterÃ­sticas no lineales
- **ElasticNet:** RegularizaciÃ³n para caracterÃ­sticas lineales
- **XGBoost:** Gradient boosting optimizado
- **LightGBM:** Gradient boosting eficiente

### TÃ©cnicas Avanzadas
- âœ… **OptimizaciÃ³n de hiperparÃ¡metros** con Optuna
- âœ… **ValidaciÃ³n cruzada temporal** para series de tiempo
- âœ… **Ensambles** de mÃºltiples modelos
- âœ… **Feature selection** automatizada

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

### MÃ©tricas Principales
- **RMSE (Root Mean Square Error)**
- **MAE (Mean Absolute Error)**
- **MAPE (Mean Absolute Percentage Error)**
- **RÂ² (Coefficient of Determination)**

### Objetivos de Performance
- ğŸ¯ **RMSE < 50.0**
- ğŸ¯ **RÂ² > 0.85**
- ğŸ¯ **MAPE < 10%**

## ğŸ“š Notebooks Incluidos

### 1ï¸âƒ£ EDA Comprehensivo (`01_EDA_Comprehensivo.ipynb`)
- AnÃ¡lisis estadÃ­stico detallado
- Visualizaciones avanzadas
- DetecciÃ³n de outliers y patrones
- AnÃ¡lisis de correlaciones

### 2ï¸âƒ£ Preprocesamiento Avanzado (`02_Preprocesamiento_Avanzado.ipynb`)
- Limpieza de datos
- Manejo de valores faltantes
- NormalizaciÃ³n y escalado
- DivisiÃ³n temporal de datos

### 3ï¸âƒ£ IngenierÃ­a de CaracterÃ­sticas (`03_Ingenieria_Caracteristicas.ipynb`)
- CaracterÃ­sticas temporales
- CaracterÃ­sticas de lag
- EstadÃ­sticas mÃ³viles
- Interacciones entre variables

### 4ï¸âƒ£ Entrenamiento de Modelos (`04_Entrenamiento_Modelos.ipynb`)
- ConfiguraciÃ³n de modelos
- OptimizaciÃ³n de hiperparÃ¡metros
- ValidaciÃ³n cruzada
- Tracking con MLflow

### 5ï¸âƒ£ EvaluaciÃ³n de Performance (`05_Evaluacion_Performance.ipynb`)
- ComparaciÃ³n de modelos
- AnÃ¡lisis de residuos
- MÃ©tricas de evaluaciÃ³n
- VisualizaciÃ³n de resultados

### 6ï¸âƒ£ Pipeline Completo (`06_Pipeline_Completo.ipynb`)
- DemostraciÃ³n end-to-end
- AutomatizaciÃ³n del flujo
- Reproducibilidad
- DocumentaciÃ³n de resultados

## ğŸ› ï¸ Herramientas y TecnologÃ­as

### Core ML Stack
- **Python 3.8+**
- **Pandas, NumPy:** ManipulaciÃ³n de datos
- **Scikit-learn:** Modelos base
- **XGBoost, LightGBM:** Gradient boosting

### MLOps Stack
- **MLflow:** Tracking de experimentos
- **DVC:** Versionado de datos
- **Optuna:** OptimizaciÃ³n de hiperparÃ¡metros
- **Great Expectations:** ValidaciÃ³n de datos

### VisualizaciÃ³n
- **Matplotlib, Seaborn:** GrÃ¡ficos estÃ¡ticos
- **Plotly:** GrÃ¡ficos interactivos
- **Jupyter Lab:** Notebooks interactivos

## ğŸ“‹ Comandos Ãštiles

```bash
# Desarrollo
make dev-setup              # ConfiguraciÃ³n completa de desarrollo
make quality-check          # VerificaciÃ³n de calidad del cÃ³digo
make test                   # Ejecutar tests

# Datos
make data-add              # AÃ±adir datos a DVC
make data-push             # Subir datos versionados
make data-pull             # Descargar datos versionados

# MLflow
make mlflow-ui             # Iniciar interfaz de MLflow
make model-register        # Registrar mejor modelo

# Jupyter
make jupyter-lab           # Iniciar Jupyter Lab
make jupyter-notebook      # Iniciar Jupyter Notebook
```

## ğŸ¯ Resultados Esperados

### Mejoras vs Proyecto Base
- âœ… **Estructura mÃ¡s organizada** y mantenible
- âœ… **EDA mÃ¡s profundo** con insights accionables
- âœ… **IngenierÃ­a de caracterÃ­sticas** mÃ¡s sofisticada
- âœ… **MÃºltiples modelos** con optimizaciÃ³n
- âœ… **Mejor performance** en mÃ©tricas clave
- âœ… **Pipeline reproducible** y automatizado

### MÃ©tricas Objetivo
- ğŸ¯ Mejorar **RÂ²** en al menos **10%**
- ğŸ¯ Reducir **RMSE** en al menos **15%**
- ğŸ¯ Implementar **versionado completo** de datos y modelos
- ğŸ¯ Lograr **reproducibilidad 100%** de experimentos

## ğŸ‘¥ Equipo 43

**Integrante:**
- [Rafael SÃ¡nchez Marmolejo] - [Site Reliability Engineer]

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

**Proyecto desarrollado para MNA - MaestrÃ­a en Inteligencia Artificial Aplicada**  
**Equipo 43 - 2025**
>>>>>>> main
