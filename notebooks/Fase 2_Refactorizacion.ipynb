{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9eab9c3",
   "metadata": {},
   "source": [
    "# 🎓 **Inteligencia Artificial Aplicada**\n",
    "\n",
    "## 🤖 **Operaciones de aprendizaje automático (Gpo 10)**\n",
    "\n",
    "### 🏛️ Tecnológico de Monterrey\n",
    "\n",
    "#### 👨‍🏫 **Profesor titular :** Dr. Gerardo Rodríguez Hernández\n",
    "#### 👩‍🏫 **Profesor titular :** Maestro Ricardo Valdez Hernández\n",
    "#### 👩‍🏫 **Profesor tutor :** Jorge Gonzales Zapata\n",
    "\n",
    "### 📊 **Fase 1 Proyecto MLOps**\n",
    "\n",
    "#### 📅 **Octubre de 2025**\n",
    "\n",
    "### 👥 Equipo 43\n",
    "\n",
    "* 🧑‍💻 **A01795645 :** Alberto Campos Hernández\n",
    "* 🧑‍💻 **A01016093 :** Oscar Enrique García García\n",
    "* 🧑‍💻 **A01795922 :** Jessica Giovana García Gómez\n",
    "* 🧑‍💻 **A01795897 :** Esteban Sebastián Guerra Espinoza\n",
    "* 🧑‍💻 **A00820345 :** Rafael Sánchez Marmolejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad88d8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional, List\n",
    "from pathlib import Path\n",
    "# Configuración global de paralelismo para todos los modelos\n",
    "N_JOBS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a0b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# CARGA DE ARCHIVOS\n",
    "# ==========================\n",
    "@dataclass\n",
    "class CargaArchivos:\n",
    "    \"\"\"Carga datasets crudos desde una carpeta.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    carpeta_raw: str | Path\n",
    "        Ruta a la carpeta que contiene los CSVs crudos.\n",
    "    nombre_modificado: str\n",
    "        Nombre del CSV \"modificado\". power_tetouan_city_modified.csv\n",
    "    \"\"\"\n",
    "\n",
    "    carpeta_raw: Path\n",
    "    nombre_modificado: str\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.carpeta_raw = Path(self.carpeta_raw)\n",
    "        self.carpeta_raw.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def leer(self) -> pd.DataFrame:\n",
    "        na_vals = [\"nan\", \"NAN\", \"NaT\", \"\"]\n",
    "        df_modificado = pd.read_csv(\n",
    "            self.carpeta_raw / self.nombre_modificado,\n",
    "            na_values=na_vals,\n",
    "            keep_default_na=True,\n",
    "        )\n",
    "        return df_modificado\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# PREPROCESAMIENTO\n",
    "# ==========================\n",
    "@dataclass\n",
    "class Preprocesamiento:\n",
    "    \"\"\"Transforma el dataset modificado en un dataset listo para modelar.\n",
    "    Pasos realizados:\n",
    "    - Elimina columna \"mixed_type_col\" si existe.\n",
    "    - Limpia y convierte DateTime con distintos formatos.\n",
    "    - Imputa DateTime faltante con vecino a ±10 min o punto medio.\n",
    "    - Imputa numéricos con mediana por columna.\n",
    "    - Maneja outliers mediante IQR + mediana rodante (ventana configurable).\n",
    "    - Crea variables de tiempo y elimina DateTime si se solicita.\n",
    "    \"\"\"\n",
    "\n",
    "    ventana_mediana: int = 25\n",
    "    eliminar_datetime: bool = True\n",
    "\n",
    "    def _drop_col_si_existe(self, df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "        return df.drop(columns=[col], errors=\"ignore\")\n",
    "\n",
    "    def _limpiar_parsear_datetime(self, df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "        s = (\n",
    "            df[col].astype(str)\n",
    "            .str.replace(r\"[\\r\\n\\t]+\", \" \", regex=True)\n",
    "            .str.strip()\n",
    "        )\n",
    "        s = s.mask(s.eq(\"\"))\n",
    "        s = s.mask(s.str.lower().eq(\"nan\"))\n",
    "\n",
    "        dt = pd.to_datetime(s, errors=\"coerce\")\n",
    "        miss = dt.isna()\n",
    "        # Segundo intento con formato explícito mm/dd/YYYY HH:MM\n",
    "        dt.loc[miss] = pd.to_datetime(\n",
    "            s[miss], format=\"%m/%d/%Y %H:%M\", errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "        # Imputación por vecinos: 10 minutos o punto medio\n",
    "        prev = dt.shift(1)\n",
    "        nxt = dt.shift(-1)\n",
    "        mask = dt.isna() & prev.notna() & nxt.notna()\n",
    "\n",
    "        m10 = mask & ((nxt - prev) == pd.Timedelta(minutes=20))\n",
    "        dt.loc[m10] = prev.loc[m10] + pd.Timedelta(minutes=10)\n",
    "\n",
    "        m_mid = mask & dt.isna()\n",
    "        if m_mid.any():\n",
    "            mid_ns = (prev[m_mid].astype(\"int64\") + nxt[m_mid].astype(\"int64\")) // 2\n",
    "            dt.loc[m_mid] = pd.to_datetime(mid_ns)\n",
    "\n",
    "        df[col] = dt\n",
    "        return df\n",
    "\n",
    "    def _imputar_numericos_mediana(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        num_cols = df.select_dtypes(include=\"number\").columns\n",
    "        medianas = df[num_cols].median()\n",
    "        df[num_cols] = df[num_cols].fillna(medianas)\n",
    "        return df\n",
    "\n",
    "    def _outliers_mediana_rodante(self, df: pd.DataFrame, col_fecha: str) -> pd.DataFrame:\n",
    "        df = df.sort_values(col_fecha).copy()\n",
    "        num = df.select_dtypes(\"number\").columns\n",
    "\n",
    "        Q1, Q3 = df[num].quantile(0.25), df[num].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lo, hi = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "        mask = (df[num] < lo) | (df[num] > hi)\n",
    "\n",
    "        for c in num:\n",
    "            rmed = (\n",
    "                df[c]\n",
    "                .rolling(window=self.ventana_mediana, center=True, min_periods=1)\n",
    "                .median()\n",
    "            )\n",
    "            df.loc[mask[c], c] = rmed[mask[c]].fillna(df[c].median())\n",
    "        return df\n",
    "\n",
    "    def _features_tiempo(self, df: pd.DataFrame, col_fecha: str) -> pd.DataFrame:\n",
    "        dt = df[col_fecha]\n",
    "        df[\"Day\"] = dt.dt.day\n",
    "        df[\"Month\"] = dt.dt.month\n",
    "        df[\"Hour\"] = dt.dt.hour\n",
    "        df[\"Minute\"] = dt.dt.minute\n",
    "        df[\"Day of Week\"] = dt.dt.dayofweek + 1\n",
    "        # Quarter\n",
    "        df[\"Quarter of Year\"] = pd.cut(\n",
    "            df[\"Month\"],\n",
    "            bins=[0, 3, 6, 9, 12],\n",
    "            labels=[1, 2, 3, 4],\n",
    "            include_lowest=True,\n",
    "        ).astype(int)\n",
    "        # Day of Year\n",
    "        df[\"Day of Year\"] = dt.dt.strftime(\"%j\").astype(int)\n",
    "        return df\n",
    "\n",
    "    def _finalizar(self, df: pd.DataFrame, col_fecha: str) -> pd.DataFrame:\n",
    "        df = df.dropna().copy()\n",
    "        if self.eliminar_datetime and col_fecha in df.columns:\n",
    "            df = df.drop(columns=[col_fecha])\n",
    "        return df\n",
    "\n",
    "    def ejecutar(self, df_modificado: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df_modificado.copy()\n",
    "        df = self._drop_col_si_existe(df, \"mixed_type_col\")\n",
    "        df = self._limpiar_parsear_datetime(df, \"DateTime\")\n",
    "        df = self._imputar_numericos_mediana(df)\n",
    "        df = self._outliers_mediana_rodante(df, \"DateTime\")\n",
    "        df = self._features_tiempo(df, \"DateTime\")\n",
    "        df = self._finalizar(df, \"DateTime\")\n",
    "        return df\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# PIPELINE CONJUNTA\n",
    "# ==========================\n",
    "\n",
    "def correr_pipeline(\n",
    "    carpeta_raw: str | Path = \"../data/raw\",\n",
    "    carpeta_processed: str | Path = \"../data/processed\",\n",
    "    nombre_salida: str = \"power_tetouan_city_processed.csv\",\n",
    "    nombre_modificado: str = \"power_tetouan_city_modified.csv\",\n",
    "    ventana_mediana: int = 25,\n",
    "    eliminar_datetime: bool = True,\n",
    ") -> Path:\n",
    "    \"\"\"Ejecuta carga + preprocesamiento y guarda el CSV final.\"\"\"\n",
    "    carpeta_processed = Path(carpeta_processed)\n",
    "    carpeta_processed.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    loader = CargaArchivos(carpeta_raw, nombre_modificado)\n",
    "    df_modificado = loader.leer()\n",
    "\n",
    "    pp = Preprocesamiento(ventana_mediana=ventana_mediana, eliminar_datetime=eliminar_datetime)\n",
    "    df_final = pp.ejecutar(df_modificado)\n",
    "\n",
    "    ruta_out = carpeta_processed / nombre_salida\n",
    "    df_final.to_csv(ruta_out, index=False)\n",
    "    return ruta_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
